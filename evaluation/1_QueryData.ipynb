{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Following variables can be set here or via papermill\n",
    "# experiment = \"experiment-baseline-with-latency-3\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import monitoring_v3\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery.job import ExtractJobConfig\n",
    "import time\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import shutil\n",
    "import subprocess\n",
    "from subprocess import PIPE\n",
    "import sharedVariables\n",
    "from sharedVariables import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Network Logs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    '../infrastructure/credentials.json')\n",
    "\n",
    "client = bigquery.Client(credentials=credentials)\n",
    "today = datetime.datetime.today()\n",
    "table_id = f\"compute_googleapis_com_vpc_flows_{today.strftime('%Y%m%d')}\"\n",
    "# table_id = 'compute_googleapis_com_vpc_flows_20210720'\n",
    "blob_name = \"export.log\"\n",
    "\n",
    "\n",
    "\n",
    "extract_conf = ExtractJobConfig()\n",
    "extract_conf.compression = 'NONE'\n",
    "extract_conf.destination_format = 'NEWLINE_DELIMITED_JSON'\n",
    "\n",
    "def getDataset(experiment, outDir): \n",
    "    ensureDirectory(outDir)\n",
    "    bucket_name = experiment + \"-log-bucket\"\n",
    "\n",
    "    destination_uri = \"gs://{}/{}\".format(bucket_name, blob_name)\n",
    "    dataset_ref = bigquery.DatasetReference(project, experiment.replace(\"-\", \"_\"))\n",
    "    table_ref = dataset_ref.table(table_id)\n",
    "\n",
    "    extract_job = client.extract_table(\n",
    "        table_ref,\n",
    "        destination_uri,\n",
    "        # Location must match that of the source table.\n",
    "        location=\"US\",\n",
    "        job_config=extract_conf\n",
    "    )  # API request\n",
    "    extract_job.result()  # Waits for job to complete.\n",
    "\n",
    "    print(\n",
    "        \"Exported {}:{}.{} to {}\".format(project, experiment, table_id, destination_uri)\n",
    "    )\n",
    "\n",
    "\n",
    "    storage_client = storage.Client(credentials=credentials)\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.download_to_filename(f\"{outdir}/gcp-flow-network.log\")\n",
    "\n",
    "    print(\n",
    "        \"Blob downloaded successfully.\"\n",
    "    )\n",
    "\n",
    "if 'experiment' not in locals():\n",
    "    for experiment in sharedVariables.experiments: \n",
    "        try: \n",
    "            getDataset(experiment)\n",
    "        except Exception as e: \n",
    "            print(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCAPs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def download_pcap(ip, outDir):\n",
    "    ensureDirectory(outDir)\n",
    "    print(\"Dowloading File\")\n",
    "    print(os.path.join(Path.cwd(), \"..\", \"cert\"))\n",
    "    # result = subprocess.run(f\"scp -i ../infrastructure/orchestrator.pem -o StrictHostKeyChecking=no orchestrator@{ip}:/captures.zip ./captures.zip\", shell=True, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n",
    "    result = subprocess.run(f\"scp -i ~/.ssh/linux_id_rsa -o StrictHostKeyChecking=no dnhb@{ip}:/captures.zip ./captures.zip\", shell=True, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n",
    "    if(result.returncode == 0):\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        raise Exception(result.stderr)\n",
    "    shutil.unpack_archive(\"./captures.zip\", outdir)\n",
    "\n",
    "if 'experiment' not in locals():\n",
    "    download_pcap(\"35.224.133.98\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Monitoring"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    '../infrastructure/credentials.json')\n",
    "\n",
    "# Our project ID\n",
    "\n",
    "monitoring_client = monitoring_v3.MetricServiceClient(credentials=credentials)\n",
    "project_name = f\"projects/{project_id}\"\n",
    "now = time.time()\n",
    "seconds = int(now)\n",
    "nanos = int((now - seconds) * 10 ** 9)\n",
    "interval = monitoring_v3.TimeInterval(\n",
    "    {\n",
    "        \"end_time\": {\"seconds\": seconds, \"nanos\": nanos},\n",
    "        # 3600 = Get the last hour of metrics\n",
    "        \"start_time\": {\"seconds\": (seconds - (3600 * 9)), \"nanos\": nanos},\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add Filter? metric.label.instance_name = \"your-instance-id\"\n",
    "results_cpu = monitoring_client.list_time_series(\n",
    "    request={\n",
    "        \"name\": project_name,\n",
    "        \"filter\": 'metric.type =  \"compute.googleapis.com/instance/cpu/utilization\"',\n",
    "        \"interval\": interval,\n",
    "        \"view\": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL,\n",
    "    }\n",
    ")\n",
    "results_io_read = monitoring_client.list_time_series(\n",
    "    request={\n",
    "        \"name\": project_name,\n",
    "        \"filter\": 'metric.type = \"compute.googleapis.com/instance/disk/read_bytes_count\"',\n",
    "        \"interval\": interval,\n",
    "        \"view\": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL,\n",
    "    }\n",
    ")\n",
    "results_io_write = monitoring_client.list_time_series(\n",
    "    request={\n",
    "        \"name\": project_name,\n",
    "        \"filter\": 'metric.type = \"compute.googleapis.com/instance/disk/write_bytes_count\"',\n",
    "        \"interval\": interval,\n",
    "        \"view\": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL,\n",
    "    }\n",
    ")\n",
    "results_iops_read = monitoring_client.list_time_series(\n",
    "    request={\n",
    "        \"name\": project_name,\n",
    "        \"filter\": 'metric.type = \"compute.googleapis.com/instance/disk/read_ops_count\"',\n",
    "        \"interval\": interval,\n",
    "        \"view\": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL,\n",
    "    }\n",
    ")\n",
    "results_iops_write = monitoring_client.list_time_series(\n",
    "    request={\n",
    "        \"name\": project_name,\n",
    "        \"filter\": 'metric.type = \"compute.googleapis.com/instance/disk/write_ops_count\"',\n",
    "        \"interval\": interval,\n",
    "        \"view\": monitoring_v3.ListTimeSeriesRequest.TimeSeriesView.FULL,\n",
    "    }\n",
    ")\n",
    "\n",
    "def loadMonitoringData(experiment, outDir): \n",
    "    ensureDirectory(outDir)\n",
    "    df = pd.DataFrame()\n",
    "    set_timestamp_column = True\n",
    "    first_len = 0\n",
    "    for ts_cpu, ts_io_read, ts_io_write, ts_iops_read, ts_iops_write in zip(results_cpu, results_io_read, results_io_write, results_iops_read, results_iops_write):\n",
    "        # print(ts)\n",
    "        label = ts_cpu.metric.labels[\"instance_name\"]\n",
    "        # print(ts_cpu)\n",
    "        if \"orchestrator\" in label:\n",
    "            # Skip Orchesrtator\n",
    "            continue\n",
    "        if label.startswith(experiment):\n",
    "            print(label + \": \" + str(len(ts_cpu.points)))\n",
    "            if set_timestamp_column:\n",
    "                first_len=len(ts_cpu.points)-1\n",
    "                print(first_len)\n",
    "                df['timestamp'] = pd.to_datetime([p.interval.start_time.ToDatetime() for p in ts_cpu.points[:first_len]])\n",
    "                set_timestamp_column = False\n",
    "            # print(ts.points[0])\n",
    "            # When deploying the vm they might take different amount of time leading to some values beeing available a minute early this leading to different length\n",
    "            # We can trim off the last values as they are orderer from most recent to last\n",
    "            df['cpu_util_' + label] = [p.value.double_value for p in ts_cpu.points[:first_len]]\n",
    "            df['io_read_' + label] = [p.value.int64_value for p in ts_io_read.points[:first_len]]\n",
    "            df['io_write_' + label] = [p.value.int64_value for p in ts_io_write.points[:first_len]]\n",
    "            df['iops_read_' + label] = [p.value.int64_value for p in ts_iops_read.points[:first_len]]\n",
    "            df['iops_write_' + label] = [p.value.int64_value for p in ts_iops_write.points[:first_len]]\n",
    "\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    columns = df.columns\n",
    "    df.to_csv(f\"{outdir}/monitoring.csv\")\n",
    "    print(f\"Gathered all Monitoring data for {experiment}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# Make sure your experiment name is included in the experiments list, otherwise only errors will occur.\n",
    "if 'experiment' not in locals():\n",
    "    for experiment in sharedVariables.experiments: \n",
    "        try: \n",
    "            loadMonitoringData(experiment)\n",
    "        except Exception as e: \n",
    "            print(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get TimeStamps"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# # Workaround for now\n",
    "# # df_sync3 = pd.read_csv(f'{outdir}/experiment-syncmesh-with-latency-3.csv')\n",
    "# # df_base3 = pd.read_csv(f'{outdir}/experiment-baseline-with-latency-3.csv')\n",
    "# df_sync3 = loadData(f'{outdir}/experiment-syncmesh-with-latency-3.log')\n",
    "# df_base3 = loadData(f'{outdir}/experiment-baseline-with-latency-3.log')\n",
    "# # df_base3.set_index('timestamp', inplace=True)\n",
    "# # df_sync3.set_index('timestamp', inplace=True)\n",
    "\n",
    "# # df_sync6 = loadData(f'{outdir}/experiment-syncmesh-with-latency-6.log')\n",
    "# # df_base6 = loadData(f'{outdir}/experiment-baseline-with-latency-6.log')\n",
    "\n",
    "# def filterDataForSeperator(df): \n",
    "#     df = df[df[\"jsonPayload.connection.src_ip\"].isin([ip_seperator, ip_orchestrator])]\n",
    "#     df = df[df[\"jsonPayload.connection.dest_ip\"].isin([ip_seperator, ip_orchestrator])]\n",
    "#     df = df[df[\"jsonPayload.connection.dest_port\"] == 443]\n",
    "#     return df\n",
    "\n",
    "# seperator_base3 = filterDataForSeperator(df_base3)\n",
    "# seperator_sync3 = filterDataForSeperator(df_sync3)\n",
    "\n",
    "# # df = df[df[\"jsonPayload.connection.dest_ip\"]]\n",
    "# print(seperator_sync3.index)\n",
    "# print(seperator_base3.index)\n",
    "# # df_base3.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Script for automatic data retrieval via papermill\n",
    "experiment = \"experiment-advanced-mongo-with-latency-3\"\n",
    "if 'experiment' in locals():\n",
    "    todaystring = datetime.datetime.today().strftime('%Y%m%d-%H')\n",
    "    outdir = f\"data/{todaystring}-{experiment}\"\n",
    "\n",
    "    f = open(os.path.join(Path.cwd(), \"..\", \"infrastructure\", \"orchestrator.txt\"), \"r\")\n",
    "    ip = f.read()\n",
    "    download_pcap(ip, outDir=outdir)\n",
    "    loadMonitoringData(experiment, outDir=outdir)\n",
    "    getDataset(experiment, outDir=outdir)\n",
    "\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dowloading File\n",
      "c:\\Develop\\GitHub\\DSPJ2021\\syncmesh\\evaluation\\..\\cert\n",
      "\n",
      "experiment-advanced-mongo-with-latency-3-node-instance-2: 165\n",
      "164\n",
      "experiment-advanced-mongo-with-latency-3-node-instance-2: 36\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Length of values (36) does not match length of index (164)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24508/4231757217.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdownload_pcap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutDir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mloadMonitoringData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutDir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mgetDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutDir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24508/904242325.py\u001b[0m in \u001b[0;36mloadMonitoringData\u001b[1;34m(experiment, outDir)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;31m# When deploying the vm they might take different amount of time leading to some values beeing available a minute early this leading to different length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;31m# We can trim off the last values as they are orderer from most recent to last\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cpu_util_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble_value\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mts_cpu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfirst_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'io_read_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64_value\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mts_io_read\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfirst_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'io_write_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64_value\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mts_io_write\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfirst_len\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3605\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3606\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3607\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3609\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3777\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \"\"\"\n\u001b[1;32m-> 3779\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3781\u001b[0m         if (\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4504\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4505\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (36) does not match length of index (164)"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9518128f597d7b00dc14729602cfd87fb7b2cf75925976bcb0d0e328a830a12b"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}